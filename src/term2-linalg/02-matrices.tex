\begin{definition}
    Пусть $R$ --- кольцо,  $I, J$ --- конечные множества.

    Тогда матрица $A$ над  $R$ --- отображение  $I \times J \to R$.

    Обычно  $I = \{1,\ldots, m\}, J = \{1, \ldots, n\}, (i, j) \mapsto a_{ij} \in R$.

    Тогда матрица $m \times n\!: (a_{ij})_{\substack{i=1..m \\ j = 1..n}}$
\end{definition}
\begin{definition}
    Множество матриц $M_{m, n}(R)$.

    При $I = J$ мы называем квадратными  $M_n(R)$.
\end{definition}

Рассмотрим матрицу $A \in M_{m, n}$. Её можно разбить на  $n$ столбцов  $(c_1 \mid c_2 \mid \ldots \mid c_n), c_i \in K^m$ и $m$ строчек:  $\begin{pmatrix} r_1 \\ r_2 \\ \ldots \\ r_n \end{pmatrix}, r_i \in \prescript{n}{}{K}$.

Также заметим, что $M_{m, n}(K)$ --- векторное пространство над  $K$. Ясно, что  $M_{m, 1}(K) \cong K^m$ и  $M_{1, m}(K) \cong \prescript{n}{}{K}$.

\begin{definition}
    Умножение матрицы на столбец: $M_{m, n}(K) \times K^n \to K^m$: $(a_{ij}, \begin{pmatrix} x_1 \\ x_2 \\ \vdots \\ x_n \end{pmatrix}) \mapsto \begin{pmatrix} y_1 \\ y_2 \\ \vdots \\ y_m \end{pmatrix}$, где $y_i = a_{i 1} x_1 + a_{i 2}x_2 + \ldots + a_{in}x_n = \sum\limits_{k=1}^n a_{ik}x_k$.

    Можно определить умножение строки на столбец:  $\begin{pmatrix} a_1 & a_2 & \ldots & a_m \end{pmatrix} \cdot \begin{pmatrix} x_1 \\ x_2 \\ \vdots \\ x_n\end{pmatrix} \leadsto \sum a_i x_i$.  Тогда умножение матрицы на столбец можно записать как $\begin{pmatrix} r_1 \\ r_2 \\ \vdots \\ r_m \end{pmatrix} \cdot X \leadsto \begin{pmatrix} r_1 \cdot X \\ r_2 \cdot X \\ \vdots \\ r_m \cdot X \end{pmatrix}$, где $r_i$ --- строчки, а $X$ - столбец.

     Тогда заметим, что умножение матриц: $A \cdot B = \begin{pmatrix} Ac_1 & Ac_2 & \ldots  & Ac_l \end{pmatrix}$.
\end{definition}
\begin{example}[СЛУ]
    Системы линейных уравнений можно записывать как матрицу.

    $\begin{cases} a_{11}x_1 + a_{12}x_2 + \dots + a_{1n}x_n = b_1 \\ a_{21}x_1 + a_{22}x_2 + \dots + a_{2n}x_n = b_1 \\ \dots \\ a_{n1}x_1 + a_{n2}x_2 + \dots + a_{nn}x_n = b_1 \end{cases}$ Тогда $(a_{ij}) = A, \begin{pmatrix} x_1 \\ x_2 \\ \vdots \\ x_n \end{pmatrix} = X, \begin{pmatrix} b_1 \\ b_2 \\ \vdots \\ b_n \end{pmatrix} = B$ и матричная запись СЛУ - $AX = B$
\end{example}
\begin{remark}
    $A \in M_{m, n}(K)$. Рассмотрим  $\mathcal{A}\!: K^n \to K^m$,  $X \mapsto A \cdot X$.
\end{remark}
\begin{statement}
    $\mathcal{A}$ --- линейное отображение. 
\end{statement}
\begin{proof}
    $\mathcal{A}(X+Y) = A \cdot X + A \cdot Y\quad \forall x, y$,  $\mathcal{A}(kX) = kA\cdot X$,  $k \in K$.
\end{proof}

Однородная СЛУ: $AX = 0$.  $A = \begin{pmatrix} c_1 & c_2 & \ldots & c_n \end{pmatrix}$. Эта система имеет только  тривиальное решение $x = \begin{pmatrix} 0 \\ 0 \\ \vdots \\ 0\end{pmatrix} \iff c_1, \ldots, c_n$ --- ЛНЗ. $c_i \in K^m, \dim K^m = m$, тогда по ЛЗЛК заметим, что если $n > m$, то  $AX=0$ имеет нетривиальное решение (т.к. уравнений $>$ неизвестных).
\Subsection{Структура линейных отображений}
\begin{example}
   $V=R^2$. Поворот вокруг $O$ --- линейное отображение. Симметрия относительно прямой --- линейное отображение, если  $0 \in l$. Проекция на  $l$ --- линейное отображение.
\end{example}
\begin{properties}
    \begin{enumerate}
        \item $\mathcal{A}(0) = 0 (x = 0 \Rightarrow \mathcal{A}(0) = 0)$.
        \item $\mathcal{A}$ --- инъекция  $\iff \mathcal{A}(x) = 0 \Rightarrow x = 0$.
        \item $x_1, x_2, \ldots, x_n$ --- ЛЗ $\Rightarrow \mathcal{A}(x_i)$ --- ЛЗ.
        \item[3'.] $\mathcal{A}$ --- инъекция:  $\{x_i \}$ --- ЛНЗ  $\Rightarrow \{\mathcal{A}(x_i)\}$ --- ЛНЗ.
        \item  $u_1, u_2, \ldots, u_n$ --- базис $U$.  $v_1, v_2, \ldots, v_n \in V$. Тогда $\exists! \mathcal{A}\!: U \to V$ такое что  $\mathcal{A}(u_i) = v_i$.
    \end{enumerate}
\end{properties}
\begin{proof}
     \begin{enumerate}
         \item $\mathcal{A}(0) = \mathcal{A}(0+0) = \mathcal{A}(0) + \mathcal{A}(0)$ 
         \item $\Rightarrow\!:$  $\mathcal{A}$ --- инъекция,  $\mathcal{A}(x) = 0, \mathcal{A}(0)=0 \Rightarrow x = 0$. 

        $\Leftarrow\!:$ От противного, пусть $x \neq y \in U : \mathcal{A}(x) = \mathcal{A}(y) \Rightarrow \mathcal{A}(x) - \mathcal{A}(y) = \mathcal{A}(x - y) = 0 \Rightarrow x - y = 0$. Противоречие.
        \item  $\sum a_i x_i = 0 \implies \sum a_i \mathcal{A}(x_i) = \sum \mathcal{A}(a_i x_i) = \mathcal{A}(\sum a_i x_i) = \mathcal{A}(0) = 0$.
        \item[3'.] Пусть $0 = \sum a_i \mathcal{A}(x_i) = \mathcal{A}(\sum a_i x_i) \implies \sum a_i x_i = 0 \Rightarrow a_i = 0$.
        \item Определим $A$: пусть  $u \in U$.  $\exists! \{a_i\}\!:\ u = \sum a_i u_i$. Положим,  $\mathcal{A}(u) = \sum a_i v_i$.  $\mathcal{A}$ --- линейно (очевидно/упражнение).

             Единственность: пусть  $\mathcal{A}_2(u_i) = v_i$, тогда  по линейности  $\mathcal{A}_2(\sum a_i u_i) = \sum a_i \mathcal{A}_2(u_i) = \sum a_i v_i = \mathcal{A}(\sum a_i u_i)$.
    \end{enumerate}
\end{proof}
\begin{definition}
    $\mathcal{A}\!: U \to V$ --- линейное отображение.

    Тогда  $\ker \mathcal{A} = \{ u \in U \mid \mathcal{A}(u) = 0\}$ --- ядро  $\mathcal{A}$.  $\Im A = \{ v \in V \mid \exists u: \mathcal{A}(u) = v\}$.
\end{definition}
\begin{properties}
    \begin{enumerate}
        \item $\ker \mathcal{A} \le U$, $\Im \mathcal{A} \le U$.
        \item $\Im \mathcal{A} = V \iff \mathcal{A}$ --- сюръекция.
        \item $\ker \mathcal{A} = \{0\} \iff \mathcal{A}$ --- инъекция.
    \end{enumerate}
\end{properties}
\begin{proof}
    \begin{enumerate}
        \item Нам нужно собственно проверить замкнутость $\ker \mathcal{A}$. Пусть $x, y \in \ker \mathcal{A} \Rightarrow \mathcal{A}(x + y) = \mathcal{A}(x) + \mathcal{A}(y) = 0$ по определению ядра. Осталось проверить замкнутость домножения на скаляр. Ну действительно, пусть $x \in \ker \mathcal{A} \Rightarrow \mathcal{A}(kx) = k \cdot \mathcal{A}(x) = 0$.\\
        $\Im \mathcal{A} \le U$ аналогично. Пусть $X, Y \in \Im \mathcal{A} \Rightarrow \exists x, y \in U : \begin{cases}\mathcal{A}(x) = X\\
        \mathcal{A}(y) = Y\end{cases} \Rightarrow \mathcal{A}(x + y) = X + Y$. Замкнутость по домножению на скаляр: пусть $x \in \Im \mathcal{A} \Rightarrow \exists x \in U : \mathcal{A}(x) = X \Rightarrow \mathcal{A}(kx) = kX$. 
        \item Это абсолютно тривиально -- просто перефразирования одного и того же: если достигаются все значения, то у каждого значения хотя бы один достигающий его аргумент и наоборот.
        \item $\Leftarrow\!:$ Очевидно, так как тогда только $\mathcal{A}(0) = 0$.\\
        $\Rightarrow\!:$ Предположим от противного: $x \neq y \in U : \mathcal{A}(x) = \mathcal{A}(y) \Rightarrow \mathcal{A}(x - y) = 0 \Rightarrow 0 \neq x - y \in \ker \mathcal{A}$. Противоречие.
    \end{enumerate}
\end{proof}
\begin{theorem}[О ядре и образе]
    $\mathcal{A}$ --- линейное отображение.
    \begin{enumerate}
        \item $\exists$ базис  $u_1, u_2, \ldots, u_k, u_{k+1}, \ldots u_n$. Причем $u_1, \ldots, u_k$ --- базис $\ker \mathcal{A}$, а  $\mathcal{A}(u_{k+1}), \ldots, \mathcal{A}(u_n)$ --- базис $\Im \mathcal{A}$.
        \item  $\dim (\ker \mathcal{A}) + \dim (\Im \mathcal{A}) = \dim U$.
    \end{enumerate}
\end{theorem}
\begin{proof}
    Рассмотрим базис $u_1, u_2, \ldots, u_k$ --- базис $\ker \mathcal{A}$. По лемме эту систему можно дополнить до базиса  $U$. Рассмотрим $u_{k+1}, \ldots, u_n$ из нового базиса. 

    Хотим доказать, что $\mathcal{A}(u_{k+1}), \ldots, \mathcal{A}(u_n)$ --- базис $\Im \mathcal{A}$. Докажем по определению, доказав линейную независимость и порождение всех векторов в пространстве.

    \begin{itemize}
        \item ЛНЗ-ть: Пусть  $\sum a_{k + i} \mathcal{A}(u_{k+i}) = 0 \Rightarrow \mathcal{A}(\sum a_{k+i} u_{k+i}) = 0 \Rightarrow \sum a_{k+i} u_{k+i} \in \ker A \Rightarrow \exists a_1, a_2, ..., a_k : \sum a_{k + i} u_{k + i} = \sum\limits_{i=1}^k (-a_i) u_i \Rightarrow \sum\limits_{i=1}^n a_i u_i = 0$. Противоречие, так как $u_1, u_2, ..., u_n$ -- базис в $U$.
        \item Порождение: Возьмём какой-нибудь $u \in U$. Докажем, что $\mathcal{A}(u)$ выражается через базис. Разложим $u$ через базис: $u = \sum\limits_{i = 1}^n a_i u_i \Rightarrow \mathcal{A}(u) = \mathcal{A}\left(\sum\limits_{i = 1}^n a_i u_i\right) = \mathcal{A}\left(\sum\limits_{i=1}^k a_i u_i\right) + \sum\limits_{i=k+1}^n a_i \mathcal{A}(u_i)$. Но $\mathcal{A}\left(\sum\limits_{i=1}^k a_i u_i\right) = 0$, так как оно лежит в ядре. Значит действительно $\mathcal{A}(u) = \sum\limits_{i=k+1}^n a_i \mathcal{A}(u_i)$.
    \end{itemize}
\end{proof}

\begin{definition}
    Пусть $U, V$ --- векторные пространства над полем $K$. 

    Тогда  $U \oplus V \coloneqq U \times V$ как множества. То есть  $(u_1, v_1) + (u_2,v_2) = (u_1+u_2, v_1 + v_2)$, $k(u, v) \coloneqq (ku, kv)$.
\end{definition}
\begin{remark}
    Пусть $\small \begin{array}{cc} u_1,\ldots, u_n &\text{--- Базис } U \\ v_1,\ldots, v_m &\text{--- Базис } V \end{array}$, $\widetilde{v_i} = (0, v_i), \widetilde{u_i} = (0, u_i)$,

    Тогда $\{\widetilde{u_i}\} \cup \{\widetilde{v_i}\}$ --- Базис $U \oplus V$.
\end{remark}
\begin{proof}
    $\forall (u, v) \in U \oplus V\!: \exists!(a_i) \exists!(b_i)\ (u, v) = (\sum a_i u_i, \sum b_i v_i)$. 

    $(u, 0) = (\sum a_i u_i)$,  $(0, v) = (\sum b_i v_i)$.
\end{proof}
\begin{remark}
    $i_u\!: U \to U \oplus V$, $u \mapsto (u, 0)$, $i_v$ --- аналогично. Инъективный гомоморфизм векторных пространств. 

    $P_u\!: U \oplus V \to U, (u, v) \mapsto u$ --- проекция.  $\Im P_u = U, \ker P_u = \Im i_v$.

    Диаграмма прямой суммы:  $U \xleftrightarrow[i_u]{P_u} U \oplus V \xleftrightarrow[i_v]{P_v} V$.  $P_ui_u = \id_u$, $P_vi_v = \id_v$,  $P_vi_u= 0_v$,  $P_u i_v = 0_u$,  $i_uP_u + i_v P_v = ???$
\end{remark}

\begin{theorem}[Формула Грассмана]
    Пусть $U, V \le W$, $U, V$ --- конечномерные.

   $\dim(U + V) = \dim U + \dim V - \dim(U \cap V)$
\end{theorem}
\begin{proof}
    Построим линейное $f\!: U \oplus V \to W, (u, v) \mapsto u + v$. $f$ --- линейное (очев/упражнение).

    Заметим, что $\Im f = U+V$,  $\ker f = \{(u, -u) \mid \begin{array}{r} u \in U \\ -u \in V \end{array} \} = \{ (u, -u) \mid u \in U \cap V \}$.

    Очевидно, что $\ker f \cong U \cap V \implies \dim (\ker f) = \dim (U \cap V)$. А по теореме о размерности ядра и образа:  $\dim V + \dim U = \dim(U \oplus V) = \dim(U + V) + \dim(U \cap V)$
\end{proof}
\begin{example}
    $K^n$, $U = \left\{ \begin{pmatrix} x_1 \\ \vdots \\ x_n \end{pmatrix} \mid a_1 x_1 + \ldots + a_n x_n = 0\right\}$ --- гиперплоскость $\dim U = n - 1$. 

    СЛУ ---  $m$ уравнений,  $m$ гиперплоскостей --- $u_1, u_2, \ldots, u_m$. Ответ --- $\bigcap\limits_{i=1}^n u_i$.

    $\dim u_1 = n - 1$. $\dim (u_1 \cap u_2) = \dim u_1 + \dim u_2 - \dim (u_1 + u_2) \ge n - 1 + n - 1 - n \ge n - 2$. Можно продолжить процесс.
\end{example}
\begin{consequence}
    Множество решений однородной СЛУ ($n$ неизвестных,  $m$ уравнений) --- пространство размерности $\ge n - m$.
\end{consequence}
\begin{remark}
    Аналогия $(+, \cap)$ c  $(\cup, \cap)$ --- неполная:  $(V_1 + V_2) \cap V_3 \neq (V_1 \cap V_3) + (V_2 \cap V_3)$, пример: три прямые на плоскости.
\end{remark}

Пусть $A \in M_{m, n}(K), A = (a_{ij})_{\substack{i = 1..m \\ j = 1..n}}$,  $\mathcal{A}\!: \begin{array}{c} K^n \to K^m \\ x \mapsto A \cdot x \end{array}$ --- линейное отображение.

$K^n - \langle e_1, \ldots, e_n \rangle, K^m = \langle \widetilde{e_1}, \ldots \widetilde{e_m} \rangle$, где $e_i$ --- вектор нулей с 1 на  $i$ строчке. Тогда 
$A e_j = \begin{pmatrix} a_{1j} \\ a_{2j} \\ \vdots \\ a_{mj} \end{pmatrix}$. 
Тогда можно сказать, что $A = \left(\begin{array}{c|c|c|c} \mathcal{A}(e_1) & \mathcal{A}(e_2) & \ldots & \mathcal{A}(e_n) \end{array} \right)$ 

\begin{consequence}
    $A, B \in M_{m, n}(K)$.  $\mathcal{A}, \mathcal{B}$ --- линейные отображения,  $\mathcal{A} = \mathcal{B} \implies A = B$.
\end{consequence}
\begin{statement}
    $A \in M_{m, n}(K)$,  $\mathcal{A}$ --- соответствующее отображение.

    $\ker \mathcal{A}$ --- множество решений однородной СЛУ с матрицей  $A$\\
    $\Im \mathcal{A}$ --- линейная оболочка столбцов $A$.
\end{statement}
\begin{proof}
    $A = \left( \begin{array}{c|c|c|c} & &  \\ C_1 & C_2 & \ldots & C_n \\ & & \end{array} \right) = \left(\begin{array}{c|c|c} & &  \\ \mathcal{A}(e_1) & \mathcal{A}(e_2) & \ldots \mathcal{A}(e_n) \\ & & \end{array} \right)$

    $\langle C_1, C_2, \ldots, C_n \rangle = \langle \{A e_i \} \rangle = \Im \mathcal{A}. \sum a_i \mathcal{A}(e_i) = \mathcal{A}(\sum a_i e_i) = \mathcal{A}(V)$. $V$ --- вектор  $\in K^n$.
\end{proof}
\begin{definition}
    $A = \left( \begin{array}{c|c|c|c} & &  \\ C_1 & C_2 & \ldots & C_n \\ & & \end{array} \right)$.

    $\dim \langle C_1, \ldots, C_n \rangle$ --- называется рангом матрицы.

    Обозначение $\rank A, \rk A, \rg A$.
    
    При $n=m$  $n-\rk A$ называется  дефектом матрицы. Дефект $\dim \ker A$.
\end{definition}
\begin{theorem}[Принцип Дирихле для векторных пространств]
    $\mathcal{A}\!: V \to V$ --- линейное отображение.  $V$ --- конечномерное.

    Тогда  $\mathcal{A}$ --- инъекция  $\iff \mathcal{A}$ --- сюръекция.
\end{theorem}
\begin{proof}
    $\dim V = n$,  $\mathcal{A}$ --- инъекция  $\iff \ker \mathcal{A} = 0 \iff \dim \ker A = 0 \iff \dim \Im A = n - 0 = n \iff \Im A = V \iff \mathcal{A}$ --- сюръекция.
\end{proof}

\begin{definition}
    Неоднородная система: $AX=B$,  $A \in M_{m, n}(K), B \in K^m$.
\end{definition}
\begin{theorem}
    Решение неоднородной и соответствующей ей однородной системы связаны:

\end{theorem}
\begin{proof}
    Пусть $X_0$ --- решение $AX=B$, тогда  $AX=B \land AX_0=B \iff A(X-X_0) = 0 \iff x - x_0 \in \ker \mathcal{A}$ --- решения соответствующей однородной $A$.
    
    $x = x_0 + v, v \in \ker \mathcal{A} $. Множество решений $x_0 + \ker \mathcal{A} = x_0 + \ker A = x_0 + \mathcal{A}^{-1}\{0\}$. 

    $\mathcal{A}^{-1}(\{A X_0\}) = X_0 + \mathcal{A}^{-1}\{0\}$.
\end{proof}

\begin{theorem}[Альтернатива Фредгольма]
    $\forall n = m$. СЛУ: $n$ уравнений, $n$ неизвестных,  $AX=B$. Пусть  $A$ --- фиксировано,  $B$ --- нефиксировано.

    Тогда верно одно из двух: 
     \begin{enumerate}
         \item однородное СЛУ имеет только тривиальное решение и неоднородное СЛУ имеет единственное решение.
         \item $AX=0$ имеет бесконечно много решений, тогда 0 или бесконечное множество решений.
    \end{enumerate}
\end{theorem}
\begin{theorem}
    $A \in M_{n, m}(K), B \in M_{l, n}(K)$. Причем  $K^m \xrightarrow[\mathcal{B}]{} B K^n \xrightarrow[\mathcal{A}]{} K^l$.

    Рассмотрим  $C = A \cdot B$,  $\mathcal{C}\!: K^m \to K^l$.  $C \coloneqq A \cdot B$, тогда  $\mathcal{C}$ --- отображения домножения  $C$.
\end{theorem}
\begin{proof}
    Докажем, что $C_1(X) = (A \cdot B) \cdot X$,  $C(X) = A \cdot (B \cdot X)$. Достаточно проверить для какого-то базиса  $K^m$.

    $e_i$ --- все нули, но на  $i$-ой строчке единица,  без волны в $K^m$, с --- в  $K^n$.  Тогда  $Be_i = \begin{pmatrix} B_{1i} \\ B_{2i} \\ \vdots \\ B_{ni} \end{pmatrix} = \sum_i b_{ki} \widetilde{e_k}$. 

    Тогда $A(Be_i) = A(\sum b_{ki} \widetilde{e_i}) = \sum b_{ki}(A\widetilde{e_k}) = \sum b_{ki} \begin{pmatrix} a_{1k} \\ a_{2k} \\ \vdots \\ a_{lk} \end{pmatrix} = \begin{pmatrix} \sum_k a_{1k} b_{ki} \\ \sum a_{2k} b_{ki} \\ \vdots \\ \sum a_{lk} b_{ki} \end{pmatrix}$, где $i$ --- фиксированный столбец. 
\end{proof}

\begin{consequence}
    Умножение матриц ассоциативно:

    $A \in M_{k, l}(K), B \in M_{l, m}(K), C \in M_{m, n}(K)$.

    Тогда $(AB)C = A(BC)$.
\end{consequence}
\begin{definition}
    При $m = n$,

    $M_n(K)$ --- кольцо квадратных матриц. Ассоциативное, но не коммутативное кольцо.
\end{definition}
\begin{example}
    $\begin{pmatrix} 0 & 0 \\ 1 & 0 \end{pmatrix} \cdot \begin{pmatrix} 1 & 0 \\ 0 & 0 \end{pmatrix} = \begin{pmatrix} 0 & 0 \\ 1 & 0 \end{pmatrix}$\\
    $\begin{pmatrix} 1 & 0 \\ 0 & 0 \end{pmatrix} \cdot \begin{pmatrix} 0 & 0 \\ 1 & 0 \end{pmatrix} = \begin{pmatrix} 0 & 0 \\ 0 & 0 \end{pmatrix}$.
\end{example}
\Subsection{Матрица линейного отображения}

$U, V$ --- векторные пространства над  $K$.  $\mathcal{A}\!: U \to V$ --- линейное.  $u_1, \ldots, u_n$ --- базис $U$,  $v_1, \ldots, v_n$ --- базис $V$. 

$\mathcal{A}(u_i) \in V \Rightarrow \mathcal{A}(u_i)$ --- линейная комбинация  $\{ v_i \}$.

Тогда  $(a_{ij})$ --- матрица линейного отображения  $\mathcal{A}$ в базисах  $\{u_i\}, \{v_i\}$.  $A = [ \mathcal{A}]_{\{u_i\}, \{v_i\}}$. Столбцы  $A$ --- столбцы координат  $\mathcal{A}(u_i)$ в базисе  $\{v_i\}$.

\begin{statement}
    $u \in U$,  $u$ --- столбец координат в базисе  $\{u_i\}$.

    Тогда  $A \cdot u$ --- столбец координат  $\mathcal{A}(u)$ в базисе  $\{v_i\}$.
\end{statement}
\begin{proof}
    Для $u_i$ это так по определению, а для остальных векторов по дистрибутивности/линейности. 
\end{proof}
\begin{remark}
    $\{u_i\}$ задает изоморфизм  $u \xrightarrow[f_u]{} K^n$,  $v \xrightarrow[f_v] K^m$.

    \[
    \begin{matrix}
        U & \xrightarrow[\mathcal{A}]{} & V \\
        f_u \downarrow & & \downarrow f_v \\
        K^n & \xrightarrow[\cdot A]{} & K^m
    \end{matrix}
    .\] 
\end{remark}
\Subsection{Матрица перехода и формулы пересчета}

$V$ --- векторное пространство.  $\id_v$ --- линейное.  $\id_v\!: V \to V$,  $\{v_i\}$ --- базис.  $[\id]_{\{v_i\}, \{u_i\}} = \begin{pmatrix} 1 & \ldots & 0 \\ \vdots & \ddots & \vdots \\ 0 & \ldots & 1 \end{pmatrix} = E_n$. Причем  $E_n$ --- единица в кольце матриц.


Пусть теперь $\{u_i\}, \{v_i\}$ --- базисы  $V$. Тогда  $[\id]_{\{v_i\}, \{u_i\}} = C = (c_{ij})$. $u_i = \sum_j c_{ji} v_{ji}$.  $\begin{pmatrix} u_1, \ldots, u_n\end{pmatrix} = \begin{pmatrix}v_1, \ldots, v_j \end{pmatrix} \cdot C$.

$x\in V$,  $x = \sum a_i u_i$,  $x = \begin{pmatrix} a_1 \\ \vdots \\ a_n \end{pmatrix} = (x)_{u_i}$.

$\chi \coloneqq \begin{pmatrix} u_1 & \ldots & u_n \end{pmatrix} \cdot X= ???$

$C$ --- матрица перехода.
 \begin{remark}
\begin{itemize}
    \item $C_{\{u_i\}, \{v_i\}} = E$
    \item $\{u_i\}, \{v_i\}, \{w_i\}$ --- базисы. Тогда $C_{\{u_i\}\{w_i\}} = C_{\{u_i\}\{v_i\}} \cdot C_{\{v_i\}\{w_i\}}$.
    \item  $C_1 = C_{\{u_i\}, \{v_i\}}, C_2 = C_{\{v_i\}, \{u_i\}}$. \\
        $C_1 \cdot C_2 = C_2 \cdot C_1 = E$. $C_1, C_2$ --- взаимообратные.
\end{itemize}
\end{remark}

Пусть $\mathcal{A}\!: U \to V$,  $U, V$ --- векторное пространства над  $K$. 

Пусть  $e_i$,  $f_i$ --- базисы $U$ и  $V$, тогда существует матрица  $A = [\mathcal{A}]_{\{e_i\}, \{f_i\}}$

Причем важный момент, что если бы было два отображения:  $U \xrightarrow{\mathcal{A}} V \xrightarrow{\mathcal{B}} W$, причем  $\{e_i\}, \{f_i\}, \{g_i\}$ --- базисы  $U, V, W$ соответственно.  Тогда  $[\mathcal{B}\mathcal{A}]_{\{e_i\}, \{g_i\}} = [\mathcal{B}]_{\{f_i\} \{g_i\} } \cdot [\mathcal{A}]_{\{e_i\}, \{f_i\}}$.

Тогда пусть $V$ --- векторное пространство, тогда  $[\id_V]_{\{e_i\}, \{f_i\}} = C$ --- матрица перехода от $e_i$ к  $f_i$,

$x \in V$  $X$ --- координаты относительно  $\{e_i\} \implies $  $C \cdot X$ --- координаты  $x$ относительно   $\{f_i\}$.

$[\id]_{\{e_i\}, \{e_i\}} = E = \begin{pmatrix} 1 & \ldots & 0 \\ 0 & 1 & \ldots \\ 0 & \ldots & 1 \end{pmatrix}$. $EA = A, AE = A$.

$[\id]_{\{f_i\}, \{e_i\}} = C^{-1}$,  $CC^{-1} = C^{-1}C = E$. Матрица перехода --- обратимы. 

\begin{definition}
    $V$ --- векторное пространство над  $K$.

    $\mathcal{A}\!: V \to V$ называется линейным оператором.
\end{definition}

Множество операторов на $V$ --- кольцо относительно  $(+, \circ)$.  $(\mathcal{A} + \mathcal{B})(V) \coloneqq \mathcal{A}(V) + \mathcal{B}(V) \quad \forall v \in V$.

$C \circ (\mathcal{A} + \mathcal{B}) = C \circ \mathcal{A} + C \circ \mathcal{B}$ --- из линейности $C$.

 \begin{definition}
     $\text{End}(V)$ --- эндоморфизм,  $\dim V = b \implies \text{End } V \cong M_n(K)$.
\end{definition}

Так как $[\mathcal{A} + \mathcal{B}]_{\{e_i\}} = [\mathcal{A}]_{\{e_i\}} + [\mathcal{B}]_{\{e_i\}}$.

$[\mathcal{A} \circ \mathcal{B}]_{\{e_i\}} = [\mathcal{A}]_{\{e_i\}} \circ [\mathcal{B}]_{\{e_i\}}$. Говоря об операторах, будем писать  $[\mathcal{A}]_{\{e_i\}}$.

$\left(M_n(K)\right)^*$ --- группа обратимых матриц, обозначение  $GL_n(k), GL(b, k)$.

\begin{example}
    $GL_1(K) = K^* = K \setminus \{0\}$.
\end{example}

$\begin{array}{llll} \mathcal{A}\!: & U & \to & V\text{ --- линейно} \\ & \{e_i\} && \{f_i\} \\ & \{e'_i\} && \{f'_i\} \end{array}$

Пусть  $A = [\mathcal{A}]_{\{e_i\}, \{f_i\}}$. Чему тогда равно  $[\mathcal{A}]_{\{e'_i\}, \{f'_i\}} = ?$

$U (\{e'\}) \xrightarrow{\id} U(\{e_i\}) \xrightarrow{\mathcal{A}} V (\{f_i\}) \xrightarrow{\id} V(\{f'_i\})$.

Тогда  $[\mathcal{A}]_{\{e'_i\}, \{f'_i\}} = [\id_v \circ \mathcal{A} \circ \id_u]_{\{e'_i\}, \{f'_i\}} = [\id_v]_{\{f_i\}, \{f'_i\}} \cdot [\mathcal{A}]_{\{e_i\}, \{f_i\}} \cdot [\id_v]_{\{e'_i\}, \{e_i\}} = C A \cdot D^{-1}$, где  $C$ --- матрица перехода от  $f_i$ к  $f'_i$,  $D$ --- матрица перехода  от $e_i$ к  $e'_i$.

Тогда:  \[
    A_{new} = C A C^{-1}
.\]

$A, B$ --- квадратные обратимые матрицы, тогда  $B = B A A^{-1}$.

\begin{theorem}[Канонический вид линейного отображения]
    $\mathcal{A}\!: V \to U$ --- линейное,  $V$ --- векторное пространство над  $K$. 

    Тогда $\exists$ базис $\{e_i\}$ в  $V$, базис  $\{f_i\}$ в  $U$,  $r \in \Z_{\ge 0}$, такие что $[\mathcal{A}]_{\{e_i\}, \{f_i\}} = \begin{array}{|c|c|} E_r & 0 \\ \hline 0 & 0 \end{array}$, где $E_r$ --- едининичная матрица размера  $r$.
\end{theorem}
\begin{proof}
    Выберем базис из теоремы о ядре и образа. $v_1, \ldots, v_k, v_{k+1}, \ldots v_n$ --- базис $V$, причем  $v_1, \ldots, v_k$ --- базис $\ker \mathcal{A} \le V$,  $\mathcal{A}(v_{k+1}), \ldots \mathcal{A}(v_n)$ --- Базис $\Im \mathcal{A} \le U$.

    На самом деле рассмотрим базис $v_{k+1}, \ldots v_n, v_1, v_2, \ldots, v_k$. Теперь $\forall i = 1..n - k$ положим $\mathcal{A}(v_k + i) = u_i$.  $u_1, u_2, \ldots, u_{n-k}$ --- базис $\Im \mathcal{A} \le U$ --- ЛНЗ.

    $u_1, u_2, \ldots u_{n-k}, \ldots, u_,$ --- базис $U$ (дополнили до базиса). 

    Тогда для  $\mathcal{A}(v_{k+i}) = u_i = 0 u_1 + 0 u_2 + \ldots + 1 \cdot u_i + 0 \ldots + 0 \cdot u_m\quad \forall i = 1..(n-k)$.

    $\mathcal(v_l) = 0 \quad \forall l=1..k$.

    Значит столбцы  $[\mathcal{A}]_{\{v_{k+1}, \ldots, v_n, v_1,\ldots, v_k\} \{u_i\}} =  \begin{array}{|c|c|} E_r & 0 \\ \hline 0 & 0 \end{array}$
\end{proof}

\begin{remark}
    $A \in M_{m, n}(K)$,  $\rk A = r$,  $\exists $ обратимые матрицы  $C, D$:  $\begin{array}{|c|c|} E_r & 0 \\ \hline 0 & 0 \end{array}$, $\rk(A) = \rk(A') = r \implies A' = \widetilde{C} A \widetilde{D}$
\end{remark}
\begin{definition}
    $A \in M_{m, n}(K)$, транспонированная матрица  $A^T \in M_{n, m}(K) (A^T)_{i, j} = (A)_{j, i} \quad \substack{\forall i=1..n \\ \forall j=1..m}$
\end{definition}
\begin{properties}
    \begin{enumerate}
        \item $(A^T)^T = A$.
        \item  $(A+B)^T = A^T + B^T$
        \item  $(AB)^T = B^T \cdot A^T$
        \item  $(A^{-1})^T = (A^T)^{-1}$
    \end{enumerate}
\end{properties}
\begin{proof}
    $1, 2$ --- очевидно.
     \begin{enumerate}
         \addtocounter{enumi}{2}
     \item $((AB)^T)_{i, j} = (AB)_{ji} = \sum\limits_{k=1}^l a_{jk}b_{ki}$.

         $(B^T\cdot A^T)_{ij} = \sum\limits_{k=1}^l (B^T)_{ik} (A^T)_{kj} = \sum\limits_{k=1}^{l} b_{ki} \cdot a_{jk}$ --- тоже самое.
     \item следует из  $3$ и  $E^R =E$.
    \end{enumerate}
\end{proof}

\begin{definition}
    $A \in M_{m, n}(K)$. Строчный ранг  $A$ --- это  $\dim \langle r_1, r_2, \ldots, r_m\rangle$, где $A = \left(\begin{array} r_1 \\ \hline r_2 \\ \hline \vdots \\ \hline r_m \end{array}\right)$. 

        Обозначение $\rk_r(A)$.
\end{definition}
\begin{theorem}[Свойства ранга]
    \begin{enumerate}
        \item $\rk A = \rk_r A, \rk A = \rk A^T, A \in M_{n, n}(K)$.
        \item  $\rk (AB) \le \min(\rk A, \rk B)$.
        \item $\rk (A+B) \le \rk (A) + \rk(B)$
        \item[2')] $A$ --- обратима $\implies \rk AB = \rk B, \rk BA = B$.
        \item $A \in M_n(K)$  $A$ --- обратима  $\iff \rk A = n$.
    \end{enumerate}
\end{theorem}
\begin{proof}
     \begin{enumerate}
         \item [4)] $A$ --- обратима $\iff$ соответственно $\mathcal{A}$  --- инъективно и сюръективно $\iff \mathcal{A}$ --- сюръекция  $\iff \Im \mathcal{A} = K^n \iff \rk \mathcal{A} = n, \dim (\Im \mathcal{A}) = n$.
         \item $\rk A = r \implies \exists C, D$ --- обратимые, такие, что  $CAD =\begin{array}{|c|c|} E_r & 0 \\ \hline 0 & 0 \end{array}$. 
             Тогда $(CAD)^T = D^TA^TC^T = \begin{array}{|c|c|} E_r & 0 \\ \hline 0 & 0 \end{array} \implies \rk A^T = r$.

             То есть  $\rk A = \rk A^T = \rk A$, то есть строчки $A$ $\leftrightarrow$ столбцы $A^T$.
         \item  $\rk AB = \dim(\Im(AB)) = \dim \{ AB \cdot x \mid x \in K^n \} \le \dim \{AY \mid Y \in K^m \}$.

             $\rk AB = \dim (\Im AB) = \dim (\Im A \mid_{\Im B}) \le \dim (\Im B)$
         \item[2')] $A$ -- обратимый  $\exists A^{-1}$.  $\rk (AB) \le \rk B$ по 2.

             $\rk B = rk(A^{-1}(AB)) \le \rk AB$ по 2. $\implies \rk AB = \rk B$.
         \item $\rk(A+B) = \dim \{(A+B)X \mid X \in U\} = \dim \{AX + BX \mid x \in U \} \le \dim \{Ax + By \mid x, y \in y\} = \dim(\Im A + \Im B) \stackrel{\text{Грасс.}}{\le} \dim \Im A + \dim \Im B = \rk A + \rk B$.
    \end{enumerate}
\end{proof}

\begin{definition}
    $\mathcal{A}\!: K^n \to K^n$ --- линейный оператор.

    $\mathcal{A}$ называется элементарным, если  $\mathcal{A}$ --- обратим и $\exists i_0, j_0\!: (\mathcal{A}(x))_i = x_i, i \neq i_0$. А $(\mathcal{A}(x))_{i_0} = x_{i_0} + kx_{j_0}$,

    Соответствующая матрица --- матрица элементарного преобразования.
\end{definition}


Разберем случаи:
\begin{enumerate}
    \item $i_0 \neq j_0: \quad \forall k \in K$ формула задает обратимое преобразование.

    $t_{i_0, j_0}(k)$ --- трансвекция: $\begin{pmatrix} x_1 \\ \vdots \\ x_{i_0} \\ \vdots  \\ x_n \end{pmatrix} \to \begin{pmatrix} x_1 \\ \vdots \\ x_{i_0} + k \cdot x_{j_0} \\ \vdots  \\ x_n \end{pmatrix}$

    Обратная матрица к трансвекции $t_{i_0, j_0}(k)$: \ $t^{-1}_{i_0, j_0}(k) = t_{i_0, j_0}(-1 \cdot k)$

    Матрица трансвекции --- единичная матрица, но на позиции $(a)_{i_0, j_0}$ стоит $k$.

    \item $i_0 = j_0: \quad (Ax)_{i=0} = (k+1) \cdot x_{i_0} = l \cdot x_{i_0} \quad (l := k+1)$ --- обратимо, если $l \neq 0$ (в общем случае $l \in K^*$). $m_{i_0}(l)$ --- дилатация, $m_{i_0}^{-1}(l) = m_{i_0}(\frac{1}{l})=m_{i_0}(\frac{1}{k+1})$.

    Матрица дилатации --- единичная матрица, но на $(a)_{i_0 j_0} = l = k + 1$.
\end{enumerate}


\begin{statement}
    \begin{enumerate}
        \item $T_{ij}(a) \cdot A$ получится из  $A$ прибавлением к  $i$-ой строке  $j$-ой строки, умноженной на  $a$.
        \item $M_i(a)\cdot A$ тоже самое, но умножением  $i$-ой строки на  $a$.
        \item  $A \cdot M_i(a)$ тоже самое, но со столбцом.
        \item  $A \cdot T_{ij}(a)$, прибавлением к  $j$-му столбцу  $i$-го столбца, умноженного на  $a$.
    \end{enumerate}
\end{statement}
\begin{proof}
    $1, 2$ следует из того что  $T_{ij}(a) \left(\begin{array}{c|c|c|c} c_1 & c_2 & \ldots & c_n \end{array} \right) = \left(\begin{array}{c|c|c|c} T_{ij}(a)c_1 & T_{ij}(a)c_2 & \ldots & T_{ij}c_n \end{array} \right)$ и тоже для $m_i$.

    А для столбцов  $1,2$ --- это определения элементарного преобразования  $3, 4$. Ну там можно транспонировать.
\end{proof}
\begin{remark}
    $E$ --- элементарная матрица  $\implies \rk(EA) = \rk(A) = \rk(AE)$, по свойству  $2'$ ранга, так как  $E$ --- обратима  $\iff$ элементарные преобразования матрицы не меняют их ранга.
\end{remark}
\begin{consequence}
    Алгоритмическое определение ранга: приведем $A$ элементарными преобразованиями к виду трапеции (результат Гаусса). Тогда количество ненулевых строчек --- ранг матрицы.
\end{consequence}
\begin{remark}
    Элементарное преобразование 3-го типа.
    $S_{ij}\!: \begin{pmatrix} x_1 \\ \vdots \\ x_i \\ \vdots \\ x_j \\ \vdots \\x_n \end{pmatrix} = \begin{pmatrix} x_1 \\ \vdots \\ x_j \\ \vdots \\ x_i \\ \vdots \\x_n \end{pmatrix}$
    Матрица $E$, где вместо единицы на  $s_{ii}$ стоят единицы на  $s_{ij}$ и  $s_{ji}$.

    $s_{ij} = m_{j}(-1)t_{ij}(1)t_{ji}(-1)t_{ij}(1)$.
\end{remark}
\begin{theorem}
    $A$ --- матрица:
    \begin{enumerate}
        \item $\exists e_1, \ldots, e_k$ --- элементарные, такие что $e_1 \cdot \ldots \cdot e_k \cdot A$ --- трапециевидная.
        \item $A \in GL_n(K) \implies \exists e_1, \ldots, e_k$ --- элементарные, такие, что $e_1 \cdot \ldots \cdot e_k \cdot A = E$.
        \item[2')] $A \in GL_n(K), \exists e_1, \ldots, e_k \quad A=e_1 \cdot \ldots \cdot e_k$.
        \item $\exists e_1, \ldots, e_k$ --- элементарные $\exists f_1,\ldots, f_l$ --- элементарные, такие что $e_1 \ldots e_k \cdot A \cdot f_1 \ldots f_l = \begin{array}{|c|c|} E_r & 0 \\ \hline 0 & 0 \end{array}$.
    \end{enumerate}
\end{theorem}
\begin{proof}
    $2^\circ$ Понятно, что $e_1, e_2, \ldots, e_k$ --- обратимы. Тогда $A$ --- обратима  $\iff$  $e_1e_2e_3\ldots e_k A = $ треугольная матрица.

    $2^\circ \to 2'^\circ$:  $A \in GL_n(K) \exists A^{-1} \in GL_n(K)$ по пункту 2  $\exists e_1, \ldots, e_k\!: e_1 \cdot e_2 \ldots \cdot e_k A^{-1} = E$.

    $2^\circ \implies 3^\circ$: Знаем, что  $\exists$ обратимые  $C, D$:  $CAD = \begin{array}{|c|c|} E_r & 0 \\ \hline 0 & 0 \end{array}$. По пункту 2  $C, D$ представимы элементарными преобразованиями.

    $1^\circ$ $A \in M_{m, n}(K)$. Индукция по  $n$.

    База: $n = 1$. Упражнение или смотри дальше (на то, что происходит в индукционном переходе).\\
    Переход: $n \to n+1$.  $A = (a_ij)_{\substack{i = 1..m \\ j=1..{n+1}}}$. Рассмотрим случаи:
    \begin{enumerate}
        \item $a_{11} \neq 0$, применим $t_{21}(-\frac{a_{21}}{a_{11}}), t_{31}(-\frac{a_{31}}{a_{11}}),\ldots, t_{m_1}(-\frac{a_{m_1}}{a_{11}})$. После домножения получим: первую строчку, в последующих в первом столбце ноль, а дальше получилась матрица с размерностью меньшей на 1.

        По индукционному переходу $\exists e_1, \ldots, e_k$ --- элементарные, $e_1 \ldots e_k A = $ трапециевидная матрица. $e_i$ можно дополнить до нашей матрицы:  $\begin{array}{c|c} 1 & 0 \\ \hline 0 & e_i \end{array}$.

        \item $a_{11} = 0$, но $\exists k\!: a_{k_1} \neq 0$. Поменяем две строчки местами.

        \item Весь первый столбец --- нули. Забьем на него и делаем шаг индукции как в п.1.
    \end{enumerate}

    \begin{statement}
        Треугольная матрица обратима $\implies$ все  $a_i \neq 0$.
    \end{statement}
    \begin{proof}
        Пусть не так. Рассмотрим такой минимальный $i$, что  $a_i = 0$. Посмотрим на столбцы. Тогда  $c_1, c_2, \ldots, c_i \in \langle e_1, \ldots, e_{i-1} \rangle \implies c_1, c_2, \ldots, c_i$ --- ЛЗ. $c_1,\ldots,c_n$ --- ЛЗ и $\rank < n \implies$ A --- необратима.
    \end{proof}
    Итого, пусть у нас есть треугольная матрица. Применим $t_{1, n}(-\frac{a_{1n}}{a_{nn}})t_{2n}(-\frac{a_{2n}}{a_{nn}})\ldots t_{n-1,n}(-\frac{a_{n-1,n}}{a_{n,n}})$ (методом Гаусса убиваем все ненулевые элементы в последнем столбце). Теперь у нас в последнем столбце везде нули, кроме последней строчки. Повторяем процесс для всех столбцов, итого получаем матрицу, где на диагонали остались $a_{ii}$, а всё остальное - нули.
\end{proof}
\begin{statement}[Алгоритм поиска обратной матрицы]
    Для того, чтобы найти обратную матрицу нужно взять матрицу $\left(\begin{array}{c|c} A & E \end{array}\right)$ и привести левую матрицу к единичной. Тогда справа будет обратная.
\end{statement}
\begin{definition}
    $A = (a_{ij}) \in M_n(K)$ называется верхнетреугольной, если  $a_{ij} = 0 \quad \forall i > j$.

     $A = (a_{ij}) \in M_n(K)$ называется нижнетреугольной, если  $a_{ij} = 0 \quad \forall j > i$.
\end{definition}
\begin{statement}
    \begin{enumerate}
        \item $LT_n(K)$,  $UT_n(K)$ (множество нижне/верхнетреугольных) --- подкольца в  $M_n(K)$.
        \item $LT_n \cap UT_n$ --- кольцо диагональных матриц  $\cong \underbrace{K \times K \times \ldots \times K}_{n \text{раз}}$
    \end{enumerate}
\end{statement}
\begin{proof}
    \slashn
    \begin{enumerate}
        \item[2.] Сложение --- очев. Умножение --- очев (записать руками и удостовериться).
        \item [1.] Очев/упражнение (очев). 
    \end{enumerate}
\end{proof}
\begin{remark}
    $A \in M_n(K) \implies \exists \mathcal{A}: K^n \rightarrow K^n (x \mapsto A\cdot x)$, тогда

    $A \in UT_n(K) \iff \forall i \in 1:n\quad \mathcal{A}(e_i) \in \langle e_1, \ldots, e_i \rangle$. $\langle e_1 \rangle \le \langle e_1, e_2 \rangle \le \ldots \le \langle e_1, \ldots, e_n \rangle$.
\end{remark}
\begin{definition}
    $A$ --- нильподентна, если $\exists k\!: A^k = 0$.
\end{definition}
\begin{statement}
    $A \in UT_n(K)$.  $A$ --- нильп.  $\iff a_{ii} = 0$.
\end{statement}
\begin{proof}
    $\begin{pmatrix} a_{11} & & * \\ & \ddots & \\ 0 & & a_{nn} \end{pmatrix}^n = \begin{pmatrix} a_{11}^n & & * \\ & \ddots & \\ 0 & & a_{nn}^n \end{pmatrix}$

    Тогда $\implies$ $\exists a_{ii} \not = 0 \implies A^n \not = 0$.

    В обратную сторону:  $\mathcal{A}(e_i) \in \langle e_1, \ldots, e_i \rangle, a_{ii} = 0$. Откуда получаем $Ae_i = b_1e_1 + b_2e_2 + \ldots + b_{i-1}e_{i-1} + 0$.

    Значит $\mathcal{A}(e_i) \in \langle e_1, \ldots, e_{i-1} \rangle \quad \forall i$. Тогда $\mathcal{A}^2(e_i) \in \langle e_1,\ldots, e_{i-2} \rangle$. Это значит, что $\mathcal{A}^i(e_i) \in \langle \rangle \implies \mathcal{A}^i(e_i) = 0$.
\end{proof}
\begin{remark}
    $A^k = 0 \iff \exists $ замена базиса  такая, что $A \in M_n(K)$ перейдет в верхнетреугольный вид.

\end{remark}
В методе Гаусса у нас есть набор преобразований $e_1e_2\ldots e_kA$. Вспомним, что $e_i$ либо перестановка строк, либо  $t_{ij}(a)$, где  $i > j$.

Пусть перестановок нет. Тогда  $e_k = t_{i_k j_k}(a) \in LT_n(K) \implies e_1 \ldots e_k \in LT_n(K)$, где $i_k > j_k$.

Тогда  $LA = U$,  $L \in LT_n, U \in UT_n$, то есть  $A = L^{-1}U$,  $L^{-1} \in LT_n$,  $U \in UT_n$. Получили  $LU$ разложение.

В общем случае сделаем в начале сделаем перестановки строк $P = s_{i_1,j_1}s_{i_2,j_2}\ldots s_{i_k,j_k}$. Тогда $PA$ - матрица, для которой $\exists LU$ - разложение. Тогда $PA = LU \implies A = P^{-1}LU$ - $LPU$-разложение на матрицу перестановки, нижне- и верхне-треугольную.
\begin{theorem}
    Следующие условия равносильны ($A \in M_n(K)$): 
    \begin{enumerate}
        \item $\exists A^{-1} (A \in GL(K) = M_n(K)^*)$.
        \item  $A = e_1 \ldots e_k$, $e_i$ --- элементарные матрицы. 
        \item $\rk A = n$.
        \item  $\mathcal{A}\!: X \mapsto A \cdot X$ --- инъективный линейный оператор: $K^n \to K^n$ .
        \item Тоже самое, но cюръективный.
        \item Если рассмотреть матрицу как систему, то для любого вектора правой части есть единственное решение  $AX = B \iff A^{-1}B = X$.
    \end{enumerate}
\end{theorem}
